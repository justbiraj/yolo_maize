{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üëãüèΩ What's up! It's [Harpreet](https://twitter.com/DataScienceHarp)\n",
        "\n",
        "I'll be guiding you through this notebook. At any point, if you get stuck or have questions, there are two ways to get in touch:\n",
        "\n",
        "1) Send me an email with your issue: harpreet.sahota@deci.ai\n",
        "\n",
        "2) Hop into the [Deep Learning Daily (powered by Deci) Discord server](https://discord.gg/p9ecgRhDR8), and let me know what your question is.\n",
        "\n",
        "---\n",
        "\n",
        "This tutorial introduces PyTorch and how to use pre-trained models for image classification. Pre-trained models offer excellent performance with minimal effort, as they have already learned visual features from large datasets.\n",
        "\n",
        "\n",
        "You'll use a ResNet-50 model pre-trained on ImageNet and fine-tune that model on the MiniPlaces dataset.\n",
        "\n",
        "\n",
        "You'll learn about datasets, dataloaders, loss functions, optimizers, data augmentation, and the training loop.\n",
        "\n",
        "This is a barebones introduction to using PyTorch. It should get you familiar with the core concepts. For a much more detailed introduction, I recommend [learnpytorch.io](https://www.learnpytorch.io)\n",
        "\n",
        "# üë®üèΩ‚Äçüîß Setting up the Environment\n",
        "You also need to install PyTorch and torchvision, which are the libraries used in this tutorial.\n",
        "\n",
        "You can install them using `pip`:"
      ],
      "metadata": {
        "id": "8WFxJpxI2K6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets"
      ],
      "metadata": {
        "id": "CeKcNzU19wVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚¨áÔ∏è Download and Prepare the Dataset\n",
        "\n",
        "You'll use the [MiniPlaces dataset](https://github.com/CSAILVision/miniplaces) for this tutorial.\n",
        "\n",
        "In typical image classification datasets, the folder structure is usually organized in a way that each class of images is stored in its own sub-folder.\n",
        "\n",
        "This is commonly referred to as the \"Image Folder\" structure.\n",
        "\n",
        "When you've downloaded and extracted the MiniPlaces dataset, you'll find the images organized into folders according to their respective classes.\n",
        "\n",
        "Image folder format looks like this:\n",
        "\n",
        "```\n",
        "miniplaces/\n",
        "|-- train/\n",
        "|   |-- class1/\n",
        "|   |   |-- image1.jpg\n",
        "|   |   |-- image2.jpg\n",
        "|   |   |-- ...\n",
        "|   |-- class2/\n",
        "|   |   |-- image1.jpg\n",
        "|   |   |-- image2.jpg\n",
        "|   |   |-- ...\n",
        "|   |-- ...\n",
        "|-- val/\n",
        "|   |-- class1/\n",
        "|   |   |-- image1.jpg\n",
        "|   |   |-- image2.jpg\n",
        "|   |   |-- ...\n",
        "|   |-- class2/\n",
        "|   |   |-- image1.jpg\n",
        "|   |   |-- image2.jpg\n",
        "|   |   |-- ...\n",
        "|   |-- ...\n",
        "```\n",
        "\n",
        "### ü™ú The following code performs several steps:\n",
        "\n",
        "1. **Download and Extract Dataset:** Downloads the MiniPlaces dataset and extracts it to the 'datasets' directory.\n",
        "\n",
        "2. **Setup Paths:** Sets up paths for the main dataset, the validation set, and creates a new directory for the test set.\n",
        "\n",
        "3. **List Classes:** Lists all the classes in the dataset by iterating over the directories in the validation set.\n",
        "\n",
        "4. **Split Validation Set:** For each class, splits the images in the validation set into a smaller validation set and a new test set using a 60/40 split.\n",
        "\n",
        "5. **Move Images:** Moves the images for the test set from the validation directory to the test directory, maintaining the original directory structure."
      ],
      "metadata": {
        "id": "WYzfBffYCtdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://dissect.csail.mit.edu/datasets/miniplaces.zip --no-check-certificate && unzip miniplaces.zip"
      ],
      "metadata": {
        "id": "x53f627oyEFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "# set the dataset path\n",
        "dataset_path = Path('miniplaces')\n",
        "val_path = dataset_path / 'val'\n",
        "\n",
        "# get the list of classes\n",
        "classes = [d.name for d in val_path.iterdir() if d.is_dir()]\n",
        "\n",
        "# create a test directory\n",
        "test_path = dataset_path / 'test'\n",
        "test_path.mkdir(exist_ok=True)\n",
        "\n",
        "# iterate over each class\n",
        "for class_name in classes:\n",
        "    class_dir = val_path / class_name\n",
        "    class_files = [f.name for f in class_dir.iterdir() if f.is_file()]\n",
        "\n",
        "    # split the validation set\n",
        "    val_files, test_files = train_test_split(class_files, test_size=0.4, random_state=42)\n",
        "\n",
        "    # create new test class directory\n",
        "    test_class_dir = test_path / class_name\n",
        "    test_class_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # move test files from validation folder to test folder\n",
        "    for test_file in test_files:\n",
        "        source = class_dir / test_file\n",
        "        destination = test_class_dir / test_file\n",
        "        shutil.move(source, destination)"
      ],
      "metadata": {
        "id": "vKNIEH2yE-Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üíæ Dataset and Dataloader\n",
        "In PyTorch, datasets and dataloaders are essential components for efficiently working with large-scale datasets during the training process.\n",
        "\n",
        "1) **Dataset**: A Dataset in PyTorch represents a collection of data. It could be in-memory data like a list of Python objects or out-of-memory data like images on a disk. The Dataset class provides a standardized way to access this data. You typically subclass the Dataset class and implement the `__getitem__` and `__len__` methods to return a single data item and the size of the dataset, respectively. PyTorch also provides several pre-defined Dataset classes like ImageFolder for common use-cases.\n",
        "\n",
        "2) **DataLoader**: While the Dataset class provides a way to access individual data items, the DataLoader class provides a way to iterate over a Dataset in batches. This is important because when training a neural network, you typically don't feed in the entire dataset at once but process it in smaller batches. The DataLoader also makes it easy to shuffle the data and use multiple subprocesses to load the data in parallel.\n",
        "\n",
        "To create datasets and dataloaders for the MiniPlaces dataset, you can use PyTorch's `ImageFolder` and `DataLoader` classes.\n",
        "\n",
        "The `ImageFolder` class allows you to load the images directly from the directory structure, and the `DataLoader` class provides an efficient way to iterate over these images during training.\n",
        "\n",
        "The following code will set up the datasets, dataloaders, and basic transforms. Here's what is happening:\n",
        "\n",
        " - The `transforms.Compose` function is used to combine a series of image transformations that will be applied to the images. Here's a breakdown of the tranforms:\n",
        "   - **Resize to 256x256**: Resize images to 256 pixels for consistency, as the final size needed is 224x224 pixels.\n",
        "   - **Random Crops of 224x224**: To prepare the image for ResNet-50 and provide data augmentation, you will randomly crop a 224x224 patch from the original 256x256 image after resizing. This will result in variations of the same image, which can enhance the model's robustness and prevent overfitting.\n",
        "   - By randomly cropping different 224x224 patches from the original 256x256 image, you're essentially creating slightly different variations of the same image.\n",
        "   - Converted to PyTorch tensors\n",
        "   - The normalization values (`[0.485, 0.456, 0.406]` for the means and `[0.229, 0.224, 0.225]` for the standard deviations) are the standard normalization parameters for ImageNet data, which is the dataset that the pre-trained ResNet model was trained on.\n",
        "    - Normalizing data is important in deep learning to adjust pixel intensity values to a standardized range, improving model performance and maximizing the usefulness of pre-trained weights. This involves using mean and standard deviation values from the ImageNet dataset to normalize pixel values in other images, ensuring they are on a similar scale and avoiding suboptimal performance due to features with larger scales.\n",
        "\n",
        " - The `ImageFolder` class is used to create datasets for the train, validation, and test sets.\n",
        "\n",
        " - The `DataLoader` class is used to create dataloaders for the datasets. The `batch_size` is set to 64, and `shuffle=True` for the training set to ensure that the training samples are shuffled before each epoch. For the validation and test sets, `shuffle=False` since the order of these samples does not matter."
      ],
      "metadata": {
        "id": "h4E8-nuDy2K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# define the transform\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # resize images to 256x256\n",
        "    transforms.RandomCrop((224, 224)),  # random crop images to 224x224\n",
        "    transforms.ToTensor(),  # convert image to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # normalize images to ImageNet mean and sd\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # resize images to 224x224\n",
        "    transforms.ToTensor(),  # convert image to PyTorch tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # normalize images to ImageNet mean and sd\n",
        "])\n",
        "\n",
        "# define the datasets\n",
        "train_dataset = datasets.ImageFolder(dataset_path / 'train', transform=train_transform)\n",
        "val_dataset = datasets.ImageFolder(dataset_path / 'val', transform=test_transform)\n",
        "test_dataset = datasets.ImageFolder(dataset_path / 'test', transform=test_transform)\n",
        "\n",
        "# define the dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "rUtmFB7i0gBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can inspect class names like so, note this only shows the first 10 classes."
      ],
      "metadata": {
        "id": "D7NHLRI88G59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.classes[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBLTwyZN8BVf",
        "outputId": "b8a67f28-316f-4f01-db3a-4c6f5025a905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abbey',\n",
              " 'airport_terminal',\n",
              " 'amphitheater',\n",
              " 'amusement_park',\n",
              " 'aquarium',\n",
              " 'aqueduct',\n",
              " 'art_gallery',\n",
              " 'assembly_line',\n",
              " 'auditorium',\n",
              " 'badlands']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And you can see the number of classes like so:"
      ],
      "metadata": {
        "id": "Pbkge4S88YjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = len(train_dataset.classes)\n",
        "print(n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-36Gj0gf8TX8",
        "outputId": "cd40990d-c130-4ad2-a995-61f0cecb9604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üë©üèΩ‚Äçü¶≥ Instantiate a Pretrained Model\n",
        "\n",
        "### üí™üèΩ Pretrained Models\n",
        "\n",
        "Pretrained models are models that are already trained on large image datasets.\n",
        "\n",
        "They can extract important features for computer vision tasks like image classification. These models save time and resources and have better performance than training a model from scratch.\n",
        "\n",
        "You can access them in PyTorch using `torchvision.models`.\n",
        "\n",
        "Here's how to instantiate a ResNet-50 model thats been pre-trained on ImageNet:"
      ],
      "metadata": {
        "id": "dxg0OHdpFAf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "# Fetch the pretrained ResNet-50 model\n",
        "model = resnet50(weights=ResNet50_Weights.DEFAULT)"
      ],
      "metadata": {
        "id": "GHI3Lab7FbPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You've successfully fetched a pre-trained ResNet-50 model!\n",
        "\n",
        "However, this model is trained on the ImageNet dataset, which has 1000 classes. You need to modify the model to work with the MiniPlaces dataset, which has 100 classes.\n",
        "\n",
        "The part of the model that you need to modify is the last fully connected layer (`fc`).\n",
        "\n",
        "This layer is responsible for producing the final output classes from the features extracted by the rest of the network. By modifying the final fully connected layer, you can fine-tune the pretrained model to classify images into the desired number of classes.\n",
        "\n",
        "Here's how you can modify the last fully connected layer to output 100 classes, note you're using `n_classes` because you defined this earlier:\n"
      ],
      "metadata": {
        "id": "fqdC0GBfFcjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Fetch the pretrained ResNet-50 model\n",
        "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "\n",
        "# Modify the last layer\n",
        "num_ftrs = model.fc.in_features  # get the number of input features for the last layer\n",
        "model.fc = nn.Linear(num_ftrs, n_classes)  # create a new layer with the same number of input features and 100 output features"
      ],
      "metadata": {
        "id": "MsZQmKFcFfvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìâ Defining the Loss Function and Optimizer\n",
        "\n",
        "### Loss Function\n",
        "\n",
        "In PyTorch, various loss functions are available for different types of tasks.\n",
        "\n",
        "For multiclass classification tasks, a commonly used loss function is `nn.CrossEntropyLoss`.\n",
        "\n",
        "This loss function combines the softmax activation and the negative log likelihood loss, making it suitable for training models to predict class probabilities.\n",
        "\n",
        "To instantiate a `nn.CrossEntropyLoss` object, we can use the following code:"
      ],
      "metadata": {
        "id": "t67rLjWwIfGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Instantiate the CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "alfVHohuIhq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèãüèæ Optimizer\n",
        "\n",
        "Optimizers play a crucial role in training neural networks.\n",
        "\n",
        " They are responsible for updating the model's parameters based on the computed gradients during the backward pass.\n",
        "\n",
        " PyTorch provides various optimizers, such as `torch.optim.SGD`, `torch.optim.Adam`, and more.\n",
        "\n",
        "You'll the Adam optimizer for training.\n",
        "\n",
        "Adam is an adaptive learning rate optimization algorithm that computes individual adaptive learning rates for different parameters. It combines the advantages of both AdaGrad and RMSProp optimizers.\n",
        "\n",
        "You instantiate an Adam optimizer named optimizer by passing the model's parameters (`model.parameters()`) to optimize and specifying the learning rate (`lr`) and weight decay (`weight_decay`) as arguments:"
      ],
      "metadata": {
        "id": "ynSNr9YmIity"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Set the learning rate and weight decay\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "\n",
        "# Instantiate the Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "uX2fTOC0Ioa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîÑ Training Loop\n",
        "\n",
        "The training loop involves several steps: forward pass, loss calculation, backward pass, parameter updates, and optional validation.\n",
        "\n",
        "You need to set up a training loop that goes through your training data in epochs (an epoch is one full pass through the entire training dataset).\n",
        "\n",
        "In each epoch, you go through each batch of your training data, use your model to generate predictions, calculate the loss with your loss function, and then use your optimizer to perform backpropagation and update the model's weights.\n",
        "\n",
        "###üéöÔ∏è Train and Eval Mode\n",
        "\n",
        "Before training your model, put it in training mode. This is done by calling `model.train()`.\n",
        "\n",
        "In training mode, certain layers of your model, such as Dropout and BatchNorm, behave differently than in evaluation mode.\n",
        "\n",
        "When you're evaluating your model, such as on a validation dataset or test dataset, switch it to evaluation mode by calling `model.eval()`.\n",
        "\n",
        "In evaluation mode, the Dropout layers don't drop out nodes and BatchNorm uses the running estimates instead of batch statistics.\n",
        "\n",
        "\n",
        "### üíª Device Config\n",
        "\n",
        "In the code below, we first check if a GPU is available using `torch.cuda.is_available()`.\n",
        "\n",
        "If it is, we assign the device as \"cuda\", indicating that we want to use the GPU. Otherwise, we assign the device as \"cpu\".\n",
        "\n",
        "You then move the model to the selected device using the `to()` method."
      ],
      "metadata": {
        "id": "PK6lCa0AIsbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# move the model to the GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the number of training epochs\n",
        "num_epochs = 2\n",
        "\n",
        "# Initialize lists for storing training metrics\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "# in your training loop, move your data to the GPU before feeding it into your model\n",
        "for epoch in range(num_epochs):\n",
        "    # Initialize metrics\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Iterate over the training dataset\n",
        "    for images, labels in train_loader:\n",
        "        # Move images and labels to the appropriate device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Parameter updates\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # Calculate average training loss and accuracy\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "\n",
        "    # Log training metrics\n",
        "    train_losses.append(average_loss)\n",
        "    train_accuracies.append(accuracy)\n",
        "\n",
        "    # Print training metrics for the current epoch\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "_hwvA91eJG11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What just happened?\n",
        "\n",
        "In the code above, you first set the number of training epochs using the `num_epochs` variable.\n",
        "\n",
        "You then iterate over each epoch.\n",
        "\n",
        "Inside the epoch loop, you initialize the metrics `total_loss`, `correct`, and `total` to keep track of the loss and accuracy during training.\n",
        "\n",
        "You also set the model to training mode using `model.train()`.\n",
        "\n",
        "Next, you iterate over the training dataloader, which provides batches of images and labels.\n",
        "\n",
        "You move the images and labels to the selected device using `to(device)`. You zero the gradients using `optimizer.zero_grad()` to avoid accumulating gradients from previous iterations.\n",
        "\n",
        "You then perform the forward pass by passing the images through the model (`model(images)`). You calculate the loss between the predicted outputs and the ground truth labels using the loss function (`criterion(outputs, labels)`).\n",
        "\n",
        "After the forward pass, you perform the backward pass using `loss.backward()` to compute the gradients of the model's parameters. You update the parameters using `optimizer.step()`.\n",
        "\n",
        "During the iteration, you update the training metrics, including the total loss, the number of correctly predicted samples (`correct`), and the total number of samples (`total`).\n",
        "\n",
        "At the end of each epoch, you calculate the average training loss and accuracy.\n",
        "\n",
        "You then print these metrics to monitor the training progress.\n",
        "\n",
        "# Training Visualization\n",
        "\n",
        "Here are the steps to log and visualize training metrics in your code:\n",
        "\n",
        "- Initialize empty lists to store training loss and accuracy for each epoch\n",
        "- Calculate the average training loss and accuracy during each epoch and append these values to the respective lists\n",
        "- Once the training loop ends, plot the training metrics using matplotlib by creating a figure with two subplots, one for training loss and one for training accuracy\n",
        "- Plot the respective lists against the epochs using `plt.plot()`\n",
        "- Set the labels and titles for the plots\n",
        "- Show the figure using `plt.show()`\n"
      ],
      "metadata": {
        "id": "FgWDMG0VJJJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training metrics\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.title(\"Training Loss over Epochs\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Training Accuracy\")\n",
        "plt.title(\"Training Accuracy over Epochs\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CyzBuTILJp-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§î Testing and Evaluation:\n",
        "\n",
        "### Model Evaluation\n",
        "\n",
        "Evaluating a model's performance on unseen data is crucial. Metrics like accuracy, precision, and recall can reveal its classification ability.\n",
        "\n",
        "In the code below does the following:\n",
        "- Input trained model and test dataloader to `evaluate_model` function\n",
        "- Set model to evaluation mode using model.`eval()`\n",
        "- Initialize variables to track sample numbers, correct and predicted positives, and actual positives\n",
        "- Iterate through test dataloader to perform inference\n",
        "- Update variables to calculate evaluation metrics such as accuracy, precision, and recall"
      ],
      "metadata": {
        "id": "s6SqPv8BKUyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()  # Switch the model to evaluation mode\n",
        "\n",
        "    # Initialize counters\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    true_positives = 0\n",
        "    predicted_positives = 0\n",
        "    actual_positives = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to calculate gradients for evaluation\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)  # Move images to the device\n",
        "            labels = labels.to(device)  # Move labels to the device\n",
        "\n",
        "            outputs = model(images)  # Get model outputs\n",
        "            _, predicted = outputs.max(1)  # Get predicted classes\n",
        "\n",
        "            # Update counters\n",
        "            total += labels.size(0)  # Total number of samples\n",
        "            correct += predicted.eq(labels).sum().item()  # Total number of correct predictions\n",
        "\n",
        "            # Count the true positives, predicted positives, and actual positives\n",
        "            true_positives += torch.logical_and(predicted == 1, labels == 1).sum().item()\n",
        "            predicted_positives += (predicted == 1).sum().item()\n",
        "            actual_positives += (labels == 1).sum().item()\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = 100.0 * correct / total  # Accuracy = correct / total\n",
        "    precision = true_positives / predicted_positives  # Precision = TP / (TP + FP)\n",
        "    recall = true_positives / actual_positives  # Recall = TP / (TP + FN)\n",
        "\n",
        "    return accuracy, precision, recall\n",
        "\n",
        "\n",
        "test_accuracy, test_precision, test_recall = evaluate_model(model, test_loader)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"Test Precision: {test_precision:.2f}\")\n",
        "print(f\"Test Recall: {test_recall:.2f}\")\n"
      ],
      "metadata": {
        "id": "ZZpkyMxYKXV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü¶æ Inference\n",
        "\n",
        "After training and evaluating the model, you can use it to make predictions on new, unseen images.\n",
        "\n",
        "The following code will:\n",
        "\n",
        "- Load a new image saved at the specified path.\n",
        "- Use PIL to load the image.\n",
        "- Convert the image to the RGB color mode.\n",
        "- Preprocess the image using a series of transformations, including:\n",
        "  - Resizing the image to match the input size expected by the model\n",
        "  -  Converting it to a tensor\n",
        "  -  Normalizing the pixel values using the ImageNet mean and standard deviation values.\n",
        "- Move the tensor to the appropriate device.\n",
        "- Use the trained model to make predictions.\n",
        "- Print the prediction"
      ],
      "metadata": {
        "id": "Iek5OZqOKnkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load and preprocess the new image\n",
        "image_path = \"/content/datasets/miniplaces/test/amphitheater/00000215.jpg\"\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# Define the transformation for the new image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Apply the transformation to the new image\n",
        "input_image = transform(image).unsqueeze(0)\n",
        "\n",
        "# Move the input image to the appropriate device\n",
        "input_image = input_image.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Make predictions on the new image\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_image)\n",
        "\n",
        "# Get the predicted class labels\n",
        "_, predicted = outputs.max(1)\n",
        "\n",
        "# Get the predicted class probabilities\n",
        "probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
        "\n",
        "# Print the predicted class label and probabilities\n",
        "class_label = predicted.item()\n",
        "class_prob = probabilities[class_label].item()\n",
        "print(f\"Predicted class: {test_dataset.classes[class_label]}\")\n",
        "print(f\"Probability: {class_prob:.2f}\")\n"
      ],
      "metadata": {
        "id": "20lBA0xIK4eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üé¨ The End!\n",
        "\n",
        "You've got the basic workflow of PyTorch down!\n",
        "\n",
        "For a much more in-depth resource on learning PyTorch, I recommend [PyTorch Zero to Mastery](https://www.learnpytorch.io/).\n",
        "\n",
        "This is the very same resource I used when I first started my Deep Learning journey, and it's served me well since then!"
      ],
      "metadata": {
        "id": "W0oQ14r2K8_q"
      }
    }
  ]
}